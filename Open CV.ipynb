{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 509, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading image\n",
    "\n",
    "boy_image = cv2.imread('boy.jpg')\n",
    "boy_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rendering image on display\n",
    "cv2.imshow('output image', boy_image)\n",
    "\n",
    "#creating clone of image\n",
    "cv2.imwrite('boy_clone.jpg', boy_image)\n",
    "cv2.imwrite('boy_clone.png', boy_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 509)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting image from rgb to gray scale\n",
    "gray_img = cv2.cvtColor(boy_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('output image', gray_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting gray scale image to binary image\n",
    "ret, binary_img = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 509)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('binary image', binary_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 509, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting image to hsv format\n",
    "hsv_image = cv2.cvtColor(boy_image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "hsv_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image in hsv format\n",
    "cv2.imshow('hsv image',hsv_image)\n",
    "\n",
    "#only hue image\n",
    "cv2.imshow('hue', hsv_image[:, :, 0])\n",
    "\n",
    "#only saturation image\n",
    "cv2.imshow('saturation', hsv_image[:, : , 1])\n",
    "\n",
    "#only value image\n",
    "cv2.imshow('value', hsv_image[:, :, 2])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((339, 509), (339, 509), (339, 509), (339, 509, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting different frames from the rgb image\n",
    "b, g, r = cv2.split(boy_image)\n",
    "\n",
    "b.shape, g.shape, r.shape, boy_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((339, 509), numpy.ndarray, array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#uint8 means 8 bit unsigned integer\n",
    "zero_arr = np.zeros(b.shape, dtype=\"uint8\")\n",
    "\n",
    "zero_arr.shape, type(zero_arr), zero_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('blue frame image', cv2.merge([b, zero_arr, zero_arr]))\n",
    "cv2.imshow('green frame image', cv2.merge([zero_arr, g, zero_arr]))\n",
    "cv2.imshow('red frame image', cv2.merge([zero_arr, zero_arr, r]))\n",
    "cv2.imshow('original image', boy_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 509)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_height, original_width = boy_image.shape[:2]\n",
    "original_height, original_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3), array([[  1.  ,   0.  , 127.25],\n",
       "        [  0.  ,   1.  ,  84.75]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#      | 1 0 Tx |\n",
    "#  T = | 0 1 Ty |\n",
    "\n",
    "\n",
    "T = np.float32([[1, 0, original_width/4],\n",
    "                [0, 1, original_height/4]])\n",
    "\n",
    "T.shape, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_image = cv2.warpAffine(boy_image, T, (original_width, original_height))\n",
    "\n",
    "cv2.imshow('original image', boy_image)\n",
    "cv2.imshow('translated image', translated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotated image\n",
    "rotated_image_matrix = cv2.getRotationMatrix2D((original_width/2, original_height/2), 120, .6)\n",
    "rotated_image = cv2.warpAffine(boy_image, rotated_image_matrix, (original_width, original_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('rotated image', rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose image\n",
    "transposed_image = cv2.transpose(boy_image)\n",
    "cv2.imshow('transposed image', transposed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image resizing\n",
    "scaled_up_image = cv2.resize(boy_image, None, fx=0.5, fy=0.5)\n",
    "cv2.imshow('scaled up image', scaled_up_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_down_image = cv2.resize(boy_image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('scaled down image', scaled_down_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = cv2.resize(boy_image, (900, 500), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('resized image', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyramid function: used to increase or decrease size of image\n",
    "scaled_down_image = cv2.pyrDown(boy_image)\n",
    "scaled_up_image = cv2.pyrUp(boy_image)\n",
    "\n",
    "#show image on screen\n",
    "cv2.imshow('original image', boy_image)\n",
    "cv2.imshow('scaled down image', scaled_down_image)\n",
    "cv2.imshow('scaled up image', scaled_up_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping image\n",
    "start_row, start_col = int(original_height*0.25), int(original_width*0.25)\n",
    "end_row, end_col = int(original_height*0.75), int(original_width*0.75)\n",
    "\n",
    "cropped_image = boy_image[start_row:end_row, start_col:end_col]\n",
    "cv2.imshow('cropped image', cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image blurring 7*7=49\n",
    "kernel = np.ones((7,7), np.float32)/49\n",
    "\n",
    "blurred = cv2.filter2D(boy_image, -1, kernel)\n",
    "cv2.imshow('blurred image', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box filter blur\n",
    "blur_img = cv2.blur(boy_image, (3,3))\n",
    "cv2.imshow('box filter', blur_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian filter blur\n",
    "gaussian_filter_blur = cv2.GaussianBlur(boy_image, (3,3), 0)\n",
    "cv2.imshow('gaussian blur image', gaussian_filter_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median filter blur\n",
    "median_filter_blur = cv2.medianBlur(boy_image, 3)\n",
    "cv2.imshow('median filter blur',median_filter_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilateral filter blur\n",
    "bilateral_filter_blur = cv2.bilateralFilter(boy_image, 9, 75, 75)\n",
    "cv2.imshow('bilateral filter blur', bilateral_filter_blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge Detection\n",
    "\n",
    "#laplacian algorithm\n",
    "laplacian_edge_detection = cv2.Laplacian(boy_image, cv2.CV_64F)\n",
    "cv2.imshow('laplacian image', laplacian_edge_detection)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#canny algorithm for edge detection\n",
    "canny_image = cv2.Canny(boy_image, 20, 200)\n",
    "cv2.imshow('canny image', canny_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing camera\n",
    "\n",
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    return_val, frame = cam.read()\n",
    "    cv2.imshow('frame is', frame)\n",
    "    if(cv2.waitKey(1) == 13):\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[ 50  74  87]\n",
      "  [ 49  68  82]\n",
      "  [ 57  70  85]\n",
      "  ...\n",
      "  [166 166 173]\n",
      "  [165 164 171]\n",
      "  [167 165 172]]\n",
      "\n",
      " [[ 55  76  88]\n",
      "  [ 60  77  90]\n",
      "  [ 68  79  94]\n",
      "  ...\n",
      "  [165 165 171]\n",
      "  [163 162 168]\n",
      "  [165 162 168]]\n",
      "\n",
      " [[ 68  81  92]\n",
      "  [ 71  82  93]\n",
      "  [ 71  79  92]\n",
      "  ...\n",
      "  [166 166 169]\n",
      "  [164 163 166]\n",
      "  [165 162 165]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 46  56  46]\n",
      "  [ 47  56  46]\n",
      "  [ 48  56  48]\n",
      "  ...\n",
      "  [ 31  54  49]\n",
      "  [ 31  54  50]\n",
      "  [ 31  53  49]]\n",
      "\n",
      " [[ 48  56  46]\n",
      "  [ 46  54  45]\n",
      "  [ 44  52  44]\n",
      "  ...\n",
      "  [ 29  53  50]\n",
      "  [ 30  52  50]\n",
      "  [ 29  51  49]]\n",
      "\n",
      " [[ 50  57  47]\n",
      "  [ 49  56  47]\n",
      "  [ 48  56  48]\n",
      "  ...\n",
      "  [ 24  48  46]\n",
      "  [ 27  50  49]\n",
      "  [ 29  51  50]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "if(cam.isOpened()):\n",
    "    return_val, frame = cam.read()\n",
    "    print(return_val)\n",
    "    print(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cam.release()\n",
    "    \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge detection using webcam\n",
    "\n",
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    return_val, frame = cam.read()\n",
    "    canny_edge_video = cv2.Canny(frame, 50, 170)\n",
    "    cv2.imshow('real video', frame)\n",
    "    cv2.imshow('canny edge detection on video', canny_edge_video)\n",
    "    if(cv2.waitKey(1) == 13):\n",
    "        break;\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original image, gray scale image, black & white image and sketch in real time\n",
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    return_val, frame = cam.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    gray_scale_video = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    cv2.imshow('gray scale video', gray_scale_video)\n",
    "    \n",
    "    ret, binary_video = cv2.threshold(gray_scale_video, 127, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('black and white video', binary_video)\n",
    "    \n",
    "    sketch_video = cv2.Canny(frame, 50, 170)\n",
    "    cv2.imshow('sketch', sketch_video)\n",
    "    \n",
    "    if(cv2.waitKey(1) == 13):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((original_width, original_height), 45, 1)\n",
    "rotated_image = cv2.warpAffine(boy_img, rotation_matrix, (original_width, original_height))\n",
    "cv2.imshow('rotated image', rotated_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True: \n",
    "    ret, frame = cam.read()\n",
    "    cv2.imshow('live cam', frame)\n",
    "    if(cv2.waitKey(1) == 13):\n",
    "        break;\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediapipe for hand recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "class DetectHand:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mpHands = mp.solutions.hands\n",
    "    \n",
    "        #identifying hand and detecting palm and tracking it with 0.6 confidence value\n",
    "        self.hands = self.mpHands.Hands(max_num_hands=1, min_detection_confidence=0.8, min_tracking_confidence=0.8)\n",
    "\n",
    "        #getting tools to draw point and connecting line\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    def detectHand(self, camFrame, camFrameRGB):\n",
    "    \n",
    "        self.detectedHand = self.hands.process(camFrameRGB)\n",
    "        \n",
    "        #if hand detected then multi_hand_landmarks return coodinates of each hand point else it returns None\n",
    "        if self.detectedHand.multi_hand_landmarks:\n",
    "            for eachHand in self.detectedHand.multi_hand_landmarks:                    \n",
    "                self.mpDraw.draw_landmarks(camFrame, eachHand, self.mpHands.HAND_CONNECTIONS)\n",
    "    \n",
    "        return camFrame\n",
    "    \n",
    "    def getHandPosition(self, camFrame):\n",
    "        \n",
    "        landMark = []\n",
    "        if self.detectedHand.multi_hand_landmarks:\n",
    "            \n",
    "            for eachHand in self.detectedHand.multi_hand_landmarks:\n",
    "                \n",
    "                for id, lm in enumerate(eachHand.landmark):\n",
    "                    \n",
    "                    cam_height, cam_width, channel = camFrame.shape\n",
    "                    \n",
    "                    x_pixel = cam_width * lm.x\n",
    "                    y_pixel = cam_height * lm.y\n",
    "                    \n",
    "                    landMark.append([id, x_pixel, y_pixel])\n",
    "        return landMark\n",
    "    \n",
    "def main():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    \n",
    "    detectHandInstance = DetectHand()\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        isCamWorking, frame = cam.read()    \n",
    "    \n",
    "        if(isCamWorking):\n",
    "            \n",
    "            #converting bgr to rgb as mp works with rgb image only\n",
    "            frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            frame = detectHandInstance.detectHand(frame, frameRGB)\n",
    "            handPosition = detectHandInstance.getHandPosition(frameRGB)\n",
    "            \n",
    "            if(len(handPosition) != 0):\n",
    "                \n",
    "                #x-ref\n",
    "                index_top_x = handPosition[8][1]\n",
    "                wrist_x = handPosition[0][1]\n",
    "                \n",
    "            cv2.imshow('Frame', frame)\n",
    "        \n",
    "            if(cv2.waitKey(1) == 13):\n",
    "                break;\n",
    "        \n",
    "        else:\n",
    "            print('error in reading cam')\n",
    "            break;\n",
    "\n",
    "    cam.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
